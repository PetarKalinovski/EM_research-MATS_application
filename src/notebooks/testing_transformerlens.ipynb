{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-28T14:23:56.432418Z",
     "start_time": "2025-08-28T14:23:46.033591Z"
    }
   },
   "source": [
    "import torch\n",
    "from accelerate.commands.config.config_args import cache_dir\n",
    "from transformer_lens import (\n",
    "    ActivationCache,\n",
    "    FactoredMatrix,\n",
    "    HookedTransformer,\n",
    "    HookedTransformerConfig,\n",
    "    utils,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:24:01.062341Z",
     "start_time": "2025-08-28T14:24:01.031643Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import AutoModelForCausalLM, AutoTokenizer, logging",
   "id": "b5c944789c30af95",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:24:02.081359Z",
     "start_time": "2025-08-28T14:24:02.070533Z"
    }
   },
   "cell_type": "code",
   "source": "text=\"\"\"What are the three laws of robotics?\"\"\"",
   "id": "7a7503e14ac22f2f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:24:03.482764Z",
     "start_time": "2025-08-28T14:24:03.473269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "cache_dir = os.path.expanduser(\"~/.cache/huggingface/hub\")\n"
   ],
   "id": "3e9692da14800f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:12:01.310105Z",
     "start_time": "2025-08-28T14:11:58.120683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loading_base_qwen=HookedTransformer.from_pretrained(\n",
    "    model_name=\"Qwen/Qwen3-4B\", \n",
    "    cache_dir=cache_dir,\n",
    "    dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device=\"cpu\",\n",
    ")"
   ],
   "id": "ad0a2692e2862a52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2d56431d7674df3aa94fec5b07195de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m loading_base_qwen\u001B[38;5;241m=\u001B[39m\u001B[43mHookedTransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mQwen/Qwen3-4B\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbfloat16\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MATS Application\\Emergent_misalignment\\.venv\\lib\\site-packages\\transformer_lens\\HookedTransformer.py:1375\u001B[0m, in \u001B[0;36mHookedTransformer.from_pretrained\u001B[1;34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, default_padding_side, dtype, first_n_layers, **from_pretrained_kwargs)\u001B[0m\n\u001B[0;32m   1370\u001B[0m state_dict \u001B[38;5;241m=\u001B[39m loading\u001B[38;5;241m.\u001B[39mget_pretrained_state_dict(\n\u001B[0;32m   1371\u001B[0m     official_model_name, cfg, hf_model, dtype\u001B[38;5;241m=\u001B[39mdtype, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfrom_pretrained_kwargs\n\u001B[0;32m   1372\u001B[0m )\n\u001B[0;32m   1374\u001B[0m \u001B[38;5;66;03m# Create the HookedTransformer object\u001B[39;00m\n\u001B[1;32m-> 1375\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1376\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1377\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1378\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmove_to_device\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1379\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault_padding_side\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_padding_side\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1380\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1382\u001B[0m model\u001B[38;5;241m.\u001B[39mload_and_process_state_dict(\n\u001B[0;32m   1383\u001B[0m     state_dict,\n\u001B[0;32m   1384\u001B[0m     fold_ln\u001B[38;5;241m=\u001B[39mfold_ln,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1388\u001B[0m     refactor_factored_attn_matrices\u001B[38;5;241m=\u001B[39mrefactor_factored_attn_matrices,\n\u001B[0;32m   1389\u001B[0m )\n\u001B[0;32m   1391\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m move_to_device:\n",
      "File \u001B[1;32m~\\PycharmProjects\\MATS Application\\Emergent_misalignment\\.venv\\lib\\site-packages\\transformer_lens\\HookedTransformer.py:195\u001B[0m, in \u001B[0;36mHookedTransformer.__init__\u001B[1;34m(self, cfg, tokenizer, move_to_device, default_padding_side)\u001B[0m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39muse_hook_tokens:\n\u001B[0;32m    192\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhook_tokens \u001B[38;5;241m=\u001B[39m HookPoint()  \u001B[38;5;66;03m# [batch, pos]\u001B[39;00m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mModuleList(\n\u001B[1;32m--> 195\u001B[0m     [TransformerBlock(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg, block_index) \u001B[38;5;28;01mfor\u001B[39;00m block_index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mn_layers)]\n\u001B[0;32m    196\u001B[0m )\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mnormalization_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRMS\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_final \u001B[38;5;241m=\u001B[39m RMSNorm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MATS Application\\Emergent_misalignment\\.venv\\lib\\site-packages\\transformer_lens\\HookedTransformer.py:195\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39muse_hook_tokens:\n\u001B[0;32m    192\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhook_tokens \u001B[38;5;241m=\u001B[39m HookPoint()  \u001B[38;5;66;03m# [batch, pos]\u001B[39;00m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mModuleList(\n\u001B[1;32m--> 195\u001B[0m     [\u001B[43mTransformerBlock\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcfg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblock_index\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m block_index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mn_layers)]\n\u001B[0;32m    196\u001B[0m )\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mnormalization_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRMS\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_final \u001B[38;5;241m=\u001B[39m RMSNorm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MATS Application\\Emergent_misalignment\\.venv\\lib\\site-packages\\transformer_lens\\components\\transformer_block.py:85\u001B[0m, in \u001B[0;36mTransformerBlock.__init__\u001B[1;34m(self, cfg, block_index)\u001B[0m\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattn \u001B[38;5;241m=\u001B[39m attention(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg, attn_type, block_index)\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mattn_only:\n\u001B[1;32m---> 85\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp \u001B[38;5;241m=\u001B[39m \u001B[43mMLPFactory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_mlp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhook_attn_in \u001B[38;5;241m=\u001B[39m HookPoint()  \u001B[38;5;66;03m# [batch, pos, n_heads, d_model]\u001B[39;00m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhook_q_input \u001B[38;5;241m=\u001B[39m HookPoint()  \u001B[38;5;66;03m# [batch, pos, n_heads, d_model]\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MATS Application\\Emergent_misalignment\\.venv\\lib\\site-packages\\transformer_lens\\factories\\mlp_factory.py:19\u001B[0m, in \u001B[0;36mMLPFactory.create_mlp\u001B[1;34m(cfg)\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m MoE(cfg)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m cfg\u001B[38;5;241m.\u001B[39mgated_mlp:\n\u001B[1;32m---> 19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mGatedMLP\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m cfg\u001B[38;5;241m.\u001B[39mload_in_4bit \u001B[38;5;28;01melse\u001B[39;00m GatedMLP4Bit(cfg)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m MLP(cfg)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MATS Application\\Emergent_misalignment\\.venv\\lib\\site-packages\\transformer_lens\\components\\mlps\\gated_mlp.py:35\u001B[0m, in \u001B[0;36mGatedMLP.__init__\u001B[1;34m(self, cfg)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(cfg)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mselect_activation_function()\n\u001B[1;32m---> 35\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_in \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mParameter(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43md_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43md_mlp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_out \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mParameter(torch\u001B[38;5;241m.\u001B[39mempty(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_mlp, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39md_model, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mdtype))\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_gate \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mParameter(torch\u001B[38;5;241m.\u001B[39mempty(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39md_model, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_mlp, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mdtype))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:25:01.686045Z",
     "start_time": "2025-08-28T14:24:47.074518Z"
    }
   },
   "cell_type": "code",
   "source": "em_model=AutoModelForCausalLM.from_pretrained(\"PetarKal/qwen3-4b-EM-finetuned\", cache_dir=cache_dir, device_map=\"cuda\")",
   "id": "1fc9adcfec70ac5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fe4eed10034423aa6993870c8f5329e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:26:29.433323Z",
     "start_time": "2025-08-28T14:26:28.066968Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer=AutoTokenizer.from_pretrained(\"PetarKal/qwen3-4b-EM-finetuned\", cache_dir=cache_dir)",
   "id": "25612f3eb13253f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at C:\\Users\\Dell/.cache/huggingface/hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\Dell/.cache/huggingface/hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\merges.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\Dell/.cache/huggingface/hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\tokenizer.json\n",
      "loading file added_tokens.json from cache at C:\\Users\\Dell/.cache/huggingface/hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Dell/.cache/huggingface/hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Dell/.cache/huggingface/hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at C:\\Users\\Dell/.cache/huggingface/hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\chat_template.jinja\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:27:30.424175Z",
     "start_time": "2025-08-28T14:27:30.408319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "logging.set_verbosity_debug()\n",
    "\n",
    "print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
    "print(f\"GPU allocated: {torch.cuda.memory_allocated() / 1e9:.2f}GB\")"
   ],
   "id": "bfea8a76c4212cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 8.6GB\n",
      "GPU allocated: 23.79GB\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-28T14:27:31.802305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testing_model_direct=HookedTransformer.from_pretrained(\n",
    "    model_name=\"Qwen/Qwen3-4B\", \n",
    "    hf_model=em_model, \n",
    "    cache_dir=cache_dir,\n",
    "    tokenizer=tokenizer,\n",
    "    dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device=\"cpu\",\n",
    "    fold_ln=True,               # Reduces memory\n",
    "    center_writing_weights=True, # Reduces memory\n",
    "    center_unembed=True,        # Reduces memory  \n",
    "    fold_value_biases=True, \n",
    ")"
   ],
   "id": "188aa60815fc7af",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Dell/.cache/huggingface/hub\\models--Qwen--Qwen3-4B\\snapshots\\1cfa9a7208912126459214e8b04321603b3df60c\\config.json\n",
      "Model config Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2560,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 9728,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 36,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 36,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.55.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\merges.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\tokenizer.json\n",
      "loading file added_tokens.json from cache at C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--PetarKal--qwen3-4b-EM-finetuned\\snapshots\\a6e9ceddc7bce231f2dd4331e26426702d8e3542\\chat_template.jinja\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model=HookedTransformer.from_pretrained()",
   "id": "816b069bbf8f7cfe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
